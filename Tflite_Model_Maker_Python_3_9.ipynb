{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TutubanaS/ML-Playground/blob/main/Tflite_Model_Maker_Python_3_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ubhAiATjXk7a",
        "outputId": "a3f6f4ed-468f-4667-c156-8a9e3182b7c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=# /env/python\n"
          ]
        }
      ],
      "source": [
        "%env PYTHONPATH = # /env/python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and install and update miniconda\n",
        "!pip install roboflow\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py39_23.3.1-0-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py39_23.3.1-0-Linux-x86_64.sh\n",
        "!./Miniconda3-py39_23.3.1-0-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda update -q conda"
      ],
      "metadata": {
        "id": "iwymZeUxYnEt",
        "outputId": "f98ca832-238f-4bba-8934-292ca55770a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.9/site-packages (1.1.49)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/site-packages (from roboflow) (4.66.5)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.9/site-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.9/site-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/site-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/site-packages (from roboflow) (1.4.7)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.9/site-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/site-packages (from roboflow) (3.9.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/site-packages (from roboflow) (11.0.0)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.9/site-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/site-packages (from roboflow) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/site-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/site-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.9/site-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.9/site-packages (from roboflow) (2.2.3)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.9/site-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->roboflow) (4.55.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->roboflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->roboflow) (6.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->roboflow) (3.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->roboflow) (24.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests->roboflow) (3.3.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->roboflow) (3.21.0)\n",
            "--2024-11-26 18:00:55--  https://repo.anaconda.com/miniconda/Miniconda3-py39_23.3.1-0-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.32.241, 104.16.191.158, 2606:4700::6810:20f1, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.32.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 70605094 (67M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-py39_23.3.1-0-Linux-x86_64.sh.1’\n",
            "\n",
            "Miniconda3-py39_23. 100%[===================>]  67.33M  93.7MB/s    in 0.7s    \n",
            "\n",
            "2024-11-26 18:00:56 (93.7 MB/s) - ‘Miniconda3-py39_23.3.1-0-Linux-x86_64.sh.1’ saved [70605094/70605094]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "                                                                               \n",
            "Installing base environment...\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... \n",
            "The environment is inconsistent, please check the package plan carefully\n",
            "The following packages are causing the inconsistency:\n",
            "\n",
            "  - defaults/linux-64::zstd==1.5.6=hc292b87_0\n",
            "done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - conda\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                     2023.01.10-h06a4308_0 --> 2024.9.24-h06a4308_0 \n",
            "  certifi                          2022.12.7-py39h06a4308_0 --> 2024.8.30-py39h06a4308_0 \n",
            "  cffi                                1.15.1-py39h5eee18b_3 --> 1.17.1-py39h1fdaa30_0 \n",
            "  charset-normalizer                     2.0.4-pyhd3eb1b0_0 --> 3.3.2-pyhd3eb1b0_0 \n",
            "  conda-package-han~                   2.0.2-py39h06a4308_0 --> 2.4.0-py39h06a4308_0 \n",
            "  conda-package-str~                   0.7.0-py39h06a4308_0 --> 0.11.0-py39h06a4308_0 \n",
            "  cryptography                        39.0.1-py39h9ce1e76_0 --> 43.0.3-py39h7825ff9_1 \n",
            "  idna                                   3.4-py39h06a4308_0 --> 3.7-py39h06a4308_0 \n",
            "  jsonpatch          pkgs/main/noarch::jsonpatch-1.32-pyhd~ --> pkgs/main/linux-64::jsonpatch-1.33-py39h06a4308_1 \n",
            "  ld_impl_linux-64                          2.38-h1181459_1 --> 2.40-h12ee557_0 \n",
            "  libffi                                   3.4.2-h6a678d5_6 --> 3.4.4-h6a678d5_1 \n",
            "  openssl                                 1.1.1t-h7f8727e_0 --> 3.0.15-h5eee18b_0 \n",
            "  packaging                             23.0-py39h06a4308_0 --> 24.1-py39h06a4308_0 \n",
            "  pycosat                              0.6.4-py39h5eee18b_0 --> 0.6.6-py39h5eee18b_1 \n",
            "  pyopenssl                           23.0.0-py39h06a4308_0 --> 24.2.1-py39h06a4308_0 \n",
            "  python                                  3.9.16-h7a1cb2a_2 --> 3.9.20-he870216_1 \n",
            "  requests                            2.28.1-py39h06a4308_1 --> 2.32.3-py39h06a4308_1 \n",
            "  ruamel.yaml.clib                     0.2.6-py39h5eee18b_1 --> 0.2.8-py39h5eee18b_0 \n",
            "  sqlite                                  3.41.1-h5eee18b_0 --> 3.45.3-h5eee18b_0 \n",
            "  tk                                      8.6.12-h1ccaba5_0 --> 8.6.14-h39e8969_0 \n",
            "  tqdm                                4.65.0-py39hb070fc8_0 --> 4.66.5-py39h2f386ee_0 \n",
            "  tzdata                                   2023c-h04d1e81_0 --> 2024b-h04d1e81_0 \n",
            "  urllib3                            1.26.15-py39h06a4308_0 --> 2.2.3-py39h06a4308_0 \n",
            "  xz                                      5.2.10-h5eee18b_1 --> 5.4.6-h5eee18b_1 \n",
            "  zlib                                    1.2.13-h5eee18b_0 --> 1.2.13-h5eee18b_1 \n",
            "  zstandard                           0.19.0-py39h5eee18b_0 --> 0.23.0-py39h2c38b39_1 \n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.9/site-packages')"
      ],
      "metadata": {
        "id": "EWedsUfmYq1s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create conda environment with python 3.9\n",
        "!conda create -n myenv python=3.9"
      ],
      "metadata": {
        "id": "4R1a1OxjYtJp",
        "outputId": "116e1e6f-c6db-4852-f811-8521b38472bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: A conda environment already exists at '/usr/local/envs/myenv'\n",
            "Remove existing environment (y/[n])? y\n",
            "\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "  current version: 23.3.1\n",
            "  latest version: 24.11.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c defaults conda\n",
            "\n",
            "Or to minimize the number of packages updated during conda update use\n",
            "\n",
            "     conda install conda=24.11.0\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/myenv\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.9\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2024.9.24-h06a4308_0 \n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n",
            "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
            "  openssl            pkgs/main/linux-64::openssl-3.0.15-h5eee18b_0 \n",
            "  pip                pkgs/main/linux-64::pip-24.2-py39h06a4308_0 \n",
            "  python             pkgs/main/linux-64::python-3.9.20-he870216_1 \n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
            "  setuptools         pkgs/main/linux-64::setuptools-75.1.0-py39h06a4308_0 \n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n",
            "  tzdata             pkgs/main/noarch::tzdata-2024b-h04d1e81_0 \n",
            "  wheel              pkgs/main/linux-64::wheel-0.44.0-py39h06a4308_0 \n",
            "  xz                 pkgs/main/linux-64::xz-5.4.6-h5eee18b_1 \n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
            "\n",
            "\n",
            "Proceed ([y]/n)? y\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "\n",
            "Preparing transaction: / \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate myenv\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your own train.py or download this existing one\n",
        "!wget https://raw.githubusercontent.com/wwfish/tflite-model-maker/main/train.py"
      ],
      "metadata": {
        "id": "uyFD8uFYbuhU",
        "outputId": "feb2c903-372e-4dfe-9af5-2334d3db4c3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-26 18:02:21--  https://raw.githubusercontent.com/wwfish/tflite-model-maker/main/train.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1886 (1.8K) [text/plain]\n",
            "Saving to: ‘train.py.1’\n",
            "\n",
            "\rtrain.py.1            0%[                    ]       0  --.-KB/s               \rtrain.py.1          100%[===================>]   1.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-26 18:02:21 (33.8 MB/s) - ‘train.py.1’ saved [1886/1886]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and Unzip Files\n",
        "!wget https://storage.googleapis.com/download.tensorflow.org/data/android_figurine.zip\n",
        "!unzip -q android_figurine.zip"
      ],
      "metadata": {
        "id": "gGP3_XQLZQ3S",
        "outputId": "b47adfbb-79a3-4f06-f584-47e14f0b8b64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-26 18:02:24--  https://storage.googleapis.com/download.tensorflow.org/data/android_figurine.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.181.207, 173.194.206.207, 173.194.193.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.181.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14333895 (14M) [application/zip]\n",
            "Saving to: ‘android_figurine.zip.1’\n",
            "\n",
            "android_figurine.zi 100%[===================>]  13.67M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-11-26 18:02:24 (123 MB/s) - ‘android_figurine.zip.1’ saved [14333895/14333895]\n",
            "\n",
            "replace android_figurine/train/IMG_0558.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace android_figurine/train/IMG_0558.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace android_figurine/train/IMG_0558.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace android_figurine/train/IMG_0564.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace android_figurine/train/IMG_0564.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies in the new environment. You need to force acitvate conda everytime\n",
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "pip install -q tflite-model-maker\n",
        "pip3 install -q pycocotools\n",
        "pip install -q ipykernel\n",
        "pip install -q numpy==1.23.4"
      ],
      "metadata": {
        "id": "XjIuOnAYYyCm",
        "outputId": "a34a030d-fc25-4b2c-a0d1-db6b57abfc13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tflite-model-maker 0.4.3 requires numpy<1.23.4,>=1.17.3, but you have numpy 1.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Download the Dataset from Roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"7iTHMNrd1RKsLfKAJfsk\")\n",
        "project = rf.workspace(\"artsee\").project(\"paintingdetection\")\n",
        "version = project.version(26)\n",
        "dataset = version.download(\"coco\")\n",
        "\n",
        "print(\"Dataset is loaded\")"
      ],
      "metadata": {
        "id": "BiBuGjRaoV3a",
        "outputId": "9e1753de-5c50-401d-9005-07135105d403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "Dataset is loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image, ExifTags, ImageOps\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# İşlenmiş görüntülerin kaydedileceği dizini tanımlayın\n",
        "processed_image_dir = '/content/PaintingDetection-26/processed_train/'\n",
        "os.makedirs(processed_image_dir, exist_ok=True)\n",
        "\n",
        "# Görüntülerin bulunduğu orijinal dizini tanımlayın\n",
        "image_dir = '/content/PaintingDetection-26/train/'\n",
        "\n",
        "# Hedef boyut (genişlik, yükseklik)\n",
        "target_size = (320, 320)  # Modelinizin beklediği boyut\n",
        "\n",
        "# EXIF verilerine göre görüntüyü otomatik yönlendiren fonksiyon\n",
        "def auto_orient_image(img):\n",
        "    try:\n",
        "        exif = img._getexif()\n",
        "        if exif is not None:\n",
        "            for tag, value in exif.items():\n",
        "                decoded = ExifTags.TAGS.get(tag, tag)\n",
        "                if decoded == 'Orientation':\n",
        "                    orientation = value\n",
        "                    break\n",
        "            else:\n",
        "                orientation = None\n",
        "\n",
        "            if orientation == 3:\n",
        "                img = img.rotate(180, expand=True)\n",
        "            elif orientation == 6:\n",
        "                img = img.rotate(270, expand=True)\n",
        "            elif orientation == 8:\n",
        "                img = img.rotate(90, expand=True)\n",
        "    except (AttributeError, KeyError, IndexError):\n",
        "        # Görüntünün EXIF yönlendirme verisi yoksa\n",
        "        pass\n",
        "    return img\n",
        "\n",
        "# Pillow sürümüne bağlı olarak yeniden örnekleme filtresini belirleyin\n",
        "def get_resample_filter():\n",
        "    try:\n",
        "        return Image.Resampling.LANCZOS  # Pillow >= 10.0.0\n",
        "    except AttributeError:\n",
        "        try:\n",
        "            return Image.LANCZOS  # Pillow >= 9.1.0\n",
        "        except AttributeError:\n",
        "            return Image.ANTIALIAS  # Pillow < 9.1.0\n",
        "\n",
        "resample = get_resample_filter()\n",
        "\n",
        "# Görüntüyü boyutlandırıp kenarlarına dolgu ekleyen fonksiyon\n",
        "def resize_with_padding(img, target_size, resample=Image.Resampling.LANCZOS):\n",
        "    # Uygun küçük boyutu hesapla\n",
        "    img.thumbnail(target_size, resample)\n",
        "\n",
        "    # Hedef boyutta siyah arka plana sahip yeni bir görüntü oluştur\n",
        "    new_img = Image.new(\"RGB\", target_size, (0, 0, 0))\n",
        "\n",
        "    # Yeniden boyutlandırılmış görüntüyü yeni görüntüye yapıştırmak için pozisyonu hesapla\n",
        "    paste_x = (target_size[0] - img.width) // 2\n",
        "    paste_y = (target_size[1] - img.height) // 2\n",
        "\n",
        "    new_img.paste(img, (paste_x, paste_y))\n",
        "    return new_img\n",
        "\n",
        "# Hata günlüğü için logging yapılandırması\n",
        "logging.basicConfig(filename='image_processing_errors.log', level=logging.ERROR,\n",
        "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
        "\n",
        "# Görüntü işleme fonksiyonu\n",
        "def process_image(filename):\n",
        "    if not filename.lower().endswith(('.jpg', '.jpeg')):\n",
        "        return\n",
        "    img_path = os.path.join(image_dir, filename)\n",
        "    processed_img_path = os.path.join(processed_image_dir, filename)\n",
        "    try:\n",
        "        with Image.open(img_path) as img:\n",
        "            # Görüntüyü otomatik yönlendir\n",
        "            img = auto_orient_image(img)\n",
        "\n",
        "            # Görüntüyü boyutlandır ve dolgu ekle\n",
        "            img = resize_with_padding(img, target_size, resample)\n",
        "\n",
        "            # İşlenmiş görüntüyü yeni dizine kaydet\n",
        "            img.save(processed_img_path, format='JPEG', quality=90)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"{filename} işlenirken hata oluştu: {e}\")\n",
        "\n",
        "# Çoklu işlem kullanarak görüntüleri işleyin\n",
        "if __name__ == \"__main__\":\n",
        "    filenames = os.listdir(image_dir)\n",
        "    with Pool(processes=os.cpu_count()) as pool:\n",
        "        list(tqdm(pool.imap(process_image, filenames), total=len(filenames)))\n",
        "    print(\"Görüntü işleme tamamlandı.\")\n"
      ],
      "metadata": {
        "id": "v33Bpgpgpq8d",
        "outputId": "36bd406c-2526-4a70-8650-17398931cd41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 424/424 [00:00<00:00, 512.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Görüntü işleme tamamlandı.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "from multiprocessing import Pool\n",
        "from functools import partial\n",
        "\n",
        "# Set a seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Define the source directory containing images and the annotations JSON\n",
        "source_dir = '/content/PaintingDetection-26/train/'\n",
        "annotations_file = os.path.join(source_dir, '_annotations.coco.json')\n",
        "\n",
        "# Define the target base directory\n",
        "base_dir = '/content/PaintingDetection-26/'\n",
        "\n",
        "# Define split ratios (ensure they sum to 1.0)\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "# Validate split ratios\n",
        "assert train_ratio + val_ratio + test_ratio == 1.0, \"Split ratios must sum to 1.0\"\n",
        "\n",
        "# Define target directories\n",
        "train_dir = os.path.join(base_dir, 'train_split/')\n",
        "val_dir = os.path.join(base_dir, 'val_split/')\n",
        "test_dir = os.path.join(base_dir, 'test_split/')\n",
        "\n",
        "# Create target directories if they don't exist\n",
        "for directory in [train_dir, val_dir, test_dir]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(filename='image_splitting_errors.log', level=logging.ERROR,\n",
        "                    format='%(asctime)s:%(levelname)s:%(message)s')\n",
        "\n",
        "# Load the annotations JSON\n",
        "with open(annotations_file, 'r') as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Extract images and annotations\n",
        "images = coco_data['images']\n",
        "annotations = coco_data['annotations']\n",
        "categories = coco_data.get('categories', [])\n",
        "\n",
        "# Shuffle images\n",
        "random.shuffle(images)\n",
        "\n",
        "# Calculate split indices\n",
        "num_images = len(images)\n",
        "train_end = int(train_ratio * num_images)\n",
        "val_end = train_end + int(val_ratio * num_images)\n",
        "\n",
        "# Split images\n",
        "train_images = images[:train_end]\n",
        "val_images = images[train_end:val_end]\n",
        "test_images = images[val_end:]\n",
        "\n",
        "# Function to create a mapping from image_id to annotations\n",
        "def map_annotations(annotations):\n",
        "    img_id_to_ann = defaultdict(list)\n",
        "    for ann in annotations:\n",
        "        img_id_to_ann[ann['image_id']].append(ann)\n",
        "    return img_id_to_ann\n",
        "\n",
        "img_id_to_ann = map_annotations(annotations)\n",
        "\n",
        "# Function to copy an image (en üst düzeyde tanımlanmış)\n",
        "def copy_image(img, source_dir, split_dir):\n",
        "    src_path = os.path.join(source_dir, img['file_name'])\n",
        "    dst_path = os.path.join(split_dir, img['file_name'])\n",
        "    try:\n",
        "        shutil.copy2(src_path, dst_path)\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error copying {img['file_name']}: {e}\")\n",
        "\n",
        "# Function to save split data with reindexed annotations\n",
        "def save_split(split_images, split_name, split_dir, img_id_to_ann, categories):\n",
        "    split_annotations = {\n",
        "        'images': split_images,\n",
        "        'annotations': [],\n",
        "        'categories': categories\n",
        "    }\n",
        "\n",
        "    new_annotation_id = 1  # Starting ID for annotations\n",
        "    for img in split_images:\n",
        "        anns = img_id_to_ann.get(img['id'], [])\n",
        "        for ann in anns:\n",
        "            ann_copy = ann.copy()\n",
        "            ann_copy['id'] = new_annotation_id\n",
        "            # image_id zaten doğru, gerekirse buraya güncelleme ekleyebilirsiniz\n",
        "            split_annotations['annotations'].append(ann_copy)\n",
        "            new_annotation_id += 1\n",
        "\n",
        "    # Save the annotations JSON\n",
        "    split_annotations_file = os.path.join(base_dir, f'{split_name}_annotations.json')\n",
        "    with open(split_annotations_file, 'w') as f:\n",
        "        json.dump(split_annotations, f, indent=4)\n",
        "\n",
        "    # Prepare the partial function with fixed source_dir and split_dir\n",
        "    copy_func = partial(copy_image, source_dir=source_dir, split_dir=split_dir)\n",
        "\n",
        "    # Copy images using multiprocessing\n",
        "    with Pool(processes=os.cpu_count()) as pool:\n",
        "        list(tqdm(pool.imap(copy_func, split_images), total=len(split_images), desc=f\"Copying {split_name} images\"))\n",
        "\n",
        "    print(f\"{split_name.capitalize()} split: {len(split_images)} images and {len(split_annotations['annotations'])} annotations saved.\")\n",
        "\n",
        "# Save each split\n",
        "save_split(train_images, 'train', train_dir, img_id_to_ann, categories)\n",
        "save_split(val_images, 'val', val_dir, img_id_to_ann, categories)\n",
        "save_split(test_images, 'test', test_dir, img_id_to_ann, categories)\n",
        "\n",
        "print(\"Dataset successfully split into train, val, and test sets.\")\n"
      ],
      "metadata": {
        "id": "qxJz5OlDptRu",
        "outputId": "ce2e80dc-0189-4f96-d76b-d00269c48d88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying train images: 100%|██████████| 338/338 [00:00<00:00, 21302.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train split: 338 images and 1499 annotations saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Copying val images: 100%|██████████| 42/42 [00:00<00:00, 20215.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val split: 42 images and 137 annotations saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Copying test images: 100%|██████████| 43/43 [00:00<00:00, 16352.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test split: 43 images and 274 annotations saved.\n",
            "Dataset successfully split into train, val, and test sets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U albumentations"
      ],
      "metadata": {
        "id": "75if_0RAp3EV",
        "outputId": "eaa52d80-3e48-4975-a227-91167c7ff2f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations\n",
            "  Downloading albumentations-1.4.21-py3-none-any.whl (227 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/227.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m225.3/227.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.9/227.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.9/site-packages (from albumentations) (2.0.2)\n",
            "Collecting albucore==0.0.20\n",
            "  Downloading albucore-0.0.20-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic>=2.7.0\n",
            "  Downloading pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.4/456.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.10.0\n",
            "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.9/site-packages (from albumentations) (4.10.0.84)\n",
            "Collecting typing-extensions>=4.9.0\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/site-packages (from albumentations) (6.0.2)\n",
            "Collecting eval-type-backport\n",
            "  Downloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
            "Collecting stringzilla>=3.10.4\n",
            "  Downloading stringzilla-3.10.10-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simsimd>=5.9.2\n",
            "  Downloading simsimd-6.2.0-cp39-cp39-manylinux_2_28_x86_64.whl (632 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.4/632.4 kB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.27.1\n",
            "  Downloading pydantic_core-2.27.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting annotated-types>=0.6.0\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: stringzilla, simsimd, typing-extensions, scipy, eval-type-backport, annotated-types, pydantic-core, albucore, pydantic, albumentations\n",
            "Successfully installed albucore-0.0.20 albumentations-1.4.21 annotated-types-0.7.0 eval-type-backport-0.2.0 pydantic-2.10.2 pydantic-core-2.27.1 scipy-1.13.1 simsimd-6.2.0 stringzilla-3.10.10 typing-extensions-4.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import albumentations as A\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import uuid\n",
        "from collections import defaultdict\n",
        "import logging\n",
        "\n",
        "def clamp_bbox(bbox, width, height):\n",
        "    \"\"\"Clamp bbox coordinates to be within image dimensions.\"\"\"\n",
        "    x, y, w, h = bbox\n",
        "    x = max(0, min(int(x), width - 1))\n",
        "    y = max(0, min(int(y), height - 1))\n",
        "    w = max(0, min(int(w), width - x))\n",
        "    h = max(0, min(int(h), height - y))\n",
        "    return [x, y, w, h]\n",
        "\n",
        "def setup_logging(log_filename):\n",
        "    \"\"\"Set up logging configuration.\"\"\"\n",
        "    logging.basicConfig(\n",
        "        filename=log_filename,\n",
        "        level=logging.ERROR,\n",
        "        format='%(asctime)s:%(levelname)s:%(message)s'\n",
        "    )\n",
        "\n",
        "def load_coco_annotations(annotations_path):\n",
        "    \"\"\"Load COCO format annotations.\"\"\"\n",
        "    with open(annotations_path, 'r') as f:\n",
        "        coco_annotations = json.load(f)\n",
        "    return coco_annotations\n",
        "\n",
        "def create_file_to_annotations_mapping(coco_annotations):\n",
        "    \"\"\"Create a mapping from image file_name to its annotations.\"\"\"\n",
        "    file_to_annotations = defaultdict(list)\n",
        "    for ann in coco_annotations.get('annotations', []):\n",
        "        image_id = ann['image_id']\n",
        "        # Retrieve the file name corresponding to the image_id\n",
        "        file_info = next((img for img in coco_annotations['images'] if img['id'] == image_id), None)\n",
        "        if file_info:\n",
        "            file_name = file_info['file_name']\n",
        "            # Keep COCO bbox format [x, y, width, height]\n",
        "            bbox = ann['bbox']\n",
        "            file_to_annotations[file_name].append({\n",
        "                'bbox': bbox,\n",
        "                'category_id': ann['category_id']\n",
        "            })\n",
        "    return file_to_annotations\n",
        "\n",
        "def define_augmentation_pipeline():\n",
        "    \"\"\"Define the augmentation pipeline.\"\"\"\n",
        "    augmentation_pipeline = A.Compose([\n",
        "        A.Rotate(limit=15, p=0.5),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.1),\n",
        "        A.RandomScale(scale_limit=0.2, p=0.7),\n",
        "        A.Affine(shear={'x': (-10, 10), 'y': (-10, 10)}, p=0.3),\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.6),\n",
        "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.4),\n",
        "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "        A.MotionBlur(blur_limit=5, p=0.2),\n",
        "        # A.CoarseDropout(max_height=40, max_width=40, max_holes=1, p=0.2),  # Removed\n",
        "        A.Perspective(scale=(0.05, 0.1), p=0.25),\n",
        "    ],\n",
        "        bbox_params=A.BboxParams(format='coco', label_fields=['category_ids'], min_visibility=0.3)\n",
        "    )\n",
        "    return augmentation_pipeline\n",
        "\n",
        "def initialize_counters(coco_annotations):\n",
        "    \"\"\"Initialize unique ID counters for images and annotations.\"\"\"\n",
        "    existing_image_ids = [img['id'] for img in coco_annotations['images']]\n",
        "    existing_annotation_ids = [ann['id'] for ann in coco_annotations.get('annotations', [])]\n",
        "    new_image_id = max(existing_image_ids) + 1 if existing_image_ids else 1\n",
        "    new_annotation_id = max(existing_annotation_ids) + 1 if existing_annotation_ids else 1\n",
        "    return new_image_id, new_annotation_id\n",
        "\n",
        "def augment_dataset(\n",
        "    split_name,\n",
        "    split_dir,\n",
        "    output_dir,\n",
        "    coco_annotations,\n",
        "    file_to_annotations,\n",
        "    augmentation_pipeline,\n",
        "    augmentations_per_image,\n",
        "    new_image_id,\n",
        "    new_annotation_id,\n",
        "    augmented_annotations\n",
        "):\n",
        "    \"\"\"Augment images in a given split.\"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for filename in tqdm(os.listdir(split_dir), desc=f\"Augmenting {split_name} images\"):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            img_path = os.path.join(split_dir, filename)\n",
        "\n",
        "            # Load the image\n",
        "            image = cv2.imread(img_path)\n",
        "            if image is None:\n",
        "                logging.error(f\"Unable to read image {img_path}. Skipping.\")\n",
        "                continue\n",
        "            height, width = image.shape[:2]\n",
        "\n",
        "            # Get the bounding boxes and labels for this image\n",
        "            image_annotations = file_to_annotations.get(filename, [])\n",
        "            if not image_annotations:\n",
        "                logging.warning(f\"No annotations found for image {filename}. Skipping augmentation.\")\n",
        "                continue\n",
        "\n",
        "            # Extract bboxes and category_ids\n",
        "            bboxes = [ann['bbox'] for ann in image_annotations]\n",
        "            category_ids = [ann['category_id'] for ann in image_annotations]\n",
        "\n",
        "            # Clamp bboxes to image dimensions\n",
        "            bboxes = [clamp_bbox(bbox, width, height) for bbox in bboxes]\n",
        "\n",
        "            for _ in range(augmentations_per_image):  # Repeat augmentation for each image\n",
        "                try:\n",
        "                    # Apply the augmentation\n",
        "                    augmented = augmentation_pipeline(image=image, bboxes=bboxes, category_ids=category_ids)\n",
        "                except ValueError as ve:\n",
        "                    logging.error(f\"Error during augmentation for image {filename}: {ve}\")\n",
        "                    continue\n",
        "\n",
        "                # Check if any bounding boxes are left after augmentation\n",
        "                if not augmented['bboxes']:\n",
        "                    logging.info(f\"All bboxes filtered out after augmentation for image {filename}. Skipping.\")\n",
        "                    continue  # Skip saving if no bboxes are visible\n",
        "\n",
        "                # Clamp augmented bboxes to image dimensions (optional, as augmentation should handle it)\n",
        "                augmented['bboxes'] = [\n",
        "                    clamp_bbox(bbox, augmented['image'].shape[1], augmented['image'].shape[0])\n",
        "                    for bbox in augmented['bboxes']\n",
        "                ]\n",
        "\n",
        "                # Create a unique filename for the augmented image\n",
        "                unique_id = uuid.uuid4().hex\n",
        "                unique_filename = f\"{os.path.splitext(filename)[0]}_aug_{unique_id}.jpg\"\n",
        "                aug_img_path = os.path.join(output_dir, unique_filename)\n",
        "\n",
        "                # Save the augmented image\n",
        "                cv2.imwrite(aug_img_path, augmented['image'])\n",
        "\n",
        "                # Add the augmented image info to annotations\n",
        "                augmented_image_info = {\n",
        "                    \"id\": new_image_id,\n",
        "                    \"file_name\": unique_filename,\n",
        "                    \"height\": augmented['image'].shape[0],\n",
        "                    \"width\": augmented['image'].shape[1],\n",
        "                    \"date_captured\": \"2024-11-13T00:00:00+00:00\"  # Adjust as needed\n",
        "                }\n",
        "                augmented_annotations[\"images\"].append(augmented_image_info)\n",
        "\n",
        "                for bbox, category_id in zip(augmented['bboxes'], augmented['category_ids']):\n",
        "                    x, y, w, h = bbox\n",
        "\n",
        "                    # Ensure that width and height are positive\n",
        "                    w = max(0.0, w)\n",
        "                    h = max(0.0, h)\n",
        "\n",
        "                    augmented_annotation = {\n",
        "                        \"id\": new_annotation_id,\n",
        "                        \"image_id\": new_image_id,\n",
        "                        \"category_id\": category_id,\n",
        "                        \"bbox\": [x, y, w, h],\n",
        "                        \"area\": w * h,\n",
        "                        \"iscrowd\": 0\n",
        "                    }\n",
        "                    augmented_annotations[\"annotations\"].append(augmented_annotation)\n",
        "                    new_annotation_id += 1\n",
        "\n",
        "                new_image_id += 1\n",
        "\n",
        "    return new_image_id, new_annotation_id\n",
        "\n",
        "def main():\n",
        "    # Define the base directory\n",
        "    base_dir = '/content/PaintingDetection-26/'\n",
        "\n",
        "    # Define split names and their respective directories and annotations\n",
        "    splits = {\n",
        "        \"train\": {\n",
        "            \"split_dir\": os.path.join(base_dir, 'train_split/'),\n",
        "            \"annotations_file\": os.path.join(base_dir, 'train_annotations.json'),\n",
        "            \"output_dir\": os.path.join(base_dir, 'train_split_augmented/'),\n",
        "            \"augmentations_per_image\": 5,\n",
        "            \"augmented_annotations\": {\n",
        "                \"images\": [],\n",
        "                \"annotations\": [],\n",
        "                \"categories\": []\n",
        "            }\n",
        "        },\n",
        "        \"val\": {\n",
        "            \"split_dir\": os.path.join(base_dir, 'val_split/'),\n",
        "            \"annotations_file\": os.path.join(base_dir, 'val_annotations.json'),\n",
        "            \"output_dir\": os.path.join(base_dir, 'val_split_augmented/'),\n",
        "            \"augmentations_per_image\": 8,\n",
        "            \"augmented_annotations\": {\n",
        "                \"images\": [],\n",
        "                \"annotations\": [],\n",
        "                \"categories\": []\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Set up logging\n",
        "    setup_logging('augmentation_errors.log')\n",
        "\n",
        "    # Define the augmentation pipeline\n",
        "    augmentation_pipeline = define_augmentation_pipeline()\n",
        "\n",
        "    for split_name, split_info in splits.items():\n",
        "        print(f\"Processing {split_name} split...\")\n",
        "\n",
        "        # Load annotations\n",
        "        coco_annotations = load_coco_annotations(split_info[\"annotations_file\"])\n",
        "\n",
        "        # Create mapping from file_name to annotations\n",
        "        file_to_annotations = create_file_to_annotations_mapping(coco_annotations)\n",
        "\n",
        "        # Initialize augmented_annotations with categories\n",
        "        split_info[\"augmented_annotations\"][\"categories\"] = coco_annotations.get(\"categories\", [])\n",
        "\n",
        "        # Initialize unique ID counters\n",
        "        new_image_id, new_annotation_id = initialize_counters(coco_annotations)\n",
        "\n",
        "        # Augment the dataset\n",
        "        new_image_id, new_annotation_id = augment_dataset(\n",
        "            split_name=split_name,\n",
        "            split_dir=split_info[\"split_dir\"],\n",
        "            output_dir=split_info[\"output_dir\"],\n",
        "            coco_annotations=coco_annotations,\n",
        "            file_to_annotations=file_to_annotations,\n",
        "            augmentation_pipeline=augmentation_pipeline,\n",
        "            augmentations_per_image=split_info[\"augmentations_per_image\"],\n",
        "            new_image_id=new_image_id,\n",
        "            new_annotation_id=new_annotation_id,\n",
        "            augmented_annotations=split_info[\"augmented_annotations\"]\n",
        "        )\n",
        "\n",
        "        # Define the path to save augmented annotations\n",
        "        augmented_annotations_path = os.path.join(\n",
        "            base_dir, f'augmented_{split_name}_annotations.json'\n",
        "        )\n",
        "\n",
        "        # Save the augmented annotations to a new JSON file\n",
        "        with open(augmented_annotations_path, 'w') as f:\n",
        "            json.dump(split_info[\"augmented_annotations\"], f, indent=4)\n",
        "\n",
        "        print(f\"{split_name.capitalize()} augmentation complete. Augmented images and annotations have been saved.\\n\")\n",
        "\n",
        "    print(\"All augmentations complete.\")\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "id": "_4w90b9ppxNQ",
        "outputId": "cd363c73-e10d-40b0-aabc-ca1b6aedfdd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of Albumentations is available: 1.4.21 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing train split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting train images: 100%|██████████| 338/338 [00:38<00:00,  8.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train augmentation complete. Augmented images and annotations have been saved.\n",
            "\n",
            "Processing val split...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Augmenting val images: 100%|██████████| 42/42 [00:07<00:00,  5.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val augmentation complete. Augmented images and annotations have been saved.\n",
            "\n",
            "All augmentations complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define the source and target directories\n",
        "source_dir = \"/content/PaintingDetection-26\"\n",
        "target_dir = \"/content/data_train\"\n",
        "\n",
        "# Define the folder structure to create\n",
        "folders = [\"train\", \"val\", \"test\", \"annotations\"]\n",
        "\n",
        "# Create the new folder structure\n",
        "for folder in folders:\n",
        "    os.makedirs(os.path.join(target_dir, folder), exist_ok=True)\n",
        "\n",
        "# Copy images to the new structure\n",
        "shutil.copytree(os.path.join(source_dir, \"train_split_augmented\"), os.path.join(target_dir, \"train2017\"), dirs_exist_ok=True)\n",
        "shutil.copytree(os.path.join(source_dir, \"val_split_augmented\"), os.path.join(target_dir, \"val2017\"), dirs_exist_ok=True)\n",
        "shutil.copytree(os.path.join(source_dir, \"test_split\"), os.path.join(target_dir, \"test2017\"), dirs_exist_ok=True)\n",
        "\n",
        "# Move and rename annotation files\n",
        "shutil.copy(\n",
        "    os.path.join(source_dir, \"augmented_train_annotations.json\"),\n",
        "    os.path.join(target_dir, \"annotations\", \"instances_train2017.json\")\n",
        ")\n",
        "shutil.copy(\n",
        "    os.path.join(source_dir, \"augmented_val_annotations.json\"),\n",
        "    os.path.join(target_dir, \"annotations\", \"instances_val2017.json\")\n",
        ")\n",
        "shutil.copy(\n",
        "    os.path.join(source_dir, \"test_annotations.json\"),\n",
        "    os.path.join(target_dir, \"annotations\", \"instances_test2017.json\")\n",
        ")\n",
        "\n",
        "print(f\"Dataset successfully restructured under {target_dir}\")\n"
      ],
      "metadata": {
        "id": "H5OcyAjZqA2M",
        "outputId": "22bfa341-1e98-446b-9303-0030835904a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset successfully restructured under /content/data_train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from xml.etree.ElementTree import Element, SubElement, tostring\n",
        "import xml.dom.minidom as minidom\n",
        "\n",
        "def create_voc_xml(image_id, annotations, image_info, output_dir, categories):\n",
        "    # Root element\n",
        "    annotation = Element('annotation')\n",
        "    folder = SubElement(annotation, 'folder')\n",
        "    folder.text = \"images\"\n",
        "    filename = SubElement(annotation, 'filename')\n",
        "    filename.text = image_info['file_name']\n",
        "\n",
        "    # Image size\n",
        "    size = SubElement(annotation, 'size')\n",
        "    SubElement(size, 'width').text = str(image_info['width'])\n",
        "    SubElement(size, 'height').text = str(image_info['height'])\n",
        "    SubElement(size, 'depth').text = '3'\n",
        "\n",
        "    # Add bounding boxes\n",
        "    for ann in annotations:\n",
        "        obj = SubElement(annotation, 'object')\n",
        "        category_name = categories[ann['category_id']]\n",
        "        SubElement(obj, 'name').text = category_name\n",
        "        SubElement(obj, 'pose').text = 'Unspecified'\n",
        "        SubElement(obj, 'truncated').text = '0'\n",
        "        SubElement(obj, 'difficult').text = '0'\n",
        "\n",
        "        bndbox = SubElement(obj, 'bndbox')\n",
        "        bbox = ann['bbox']\n",
        "        SubElement(bndbox, 'xmin').text = str(int(bbox[0]))\n",
        "        SubElement(bndbox, 'ymin').text = str(int(bbox[1]))\n",
        "        SubElement(bndbox, 'xmax').text = str(int(bbox[0] + bbox[2]))\n",
        "        SubElement(bndbox, 'ymax').text = str(int(bbox[1] + bbox[3]))\n",
        "\n",
        "    # Write XML to file\n",
        "    xml_str = minidom.parseString(tostring(annotation)).toprettyxml(indent=\"   \")\n",
        "    xml_path = os.path.join(output_dir, f\"{image_id}.xml\")\n",
        "    with open(xml_path, \"w\") as f:\n",
        "        f.write(xml_str)\n",
        "\n",
        "# Paths\n",
        "coco_json_path = \"data_train/annotations/instances_train2017.json\"  # COCO JSON dosyasının yolu\n",
        "output_dir = \"data_train/annotations/voc_train\"  # PASCAL VOC XML dosyalarının kaydedileceği yer\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load COCO JSON\n",
        "with open(coco_json_path) as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Process images and annotations\n",
        "images = {img['id']: img for img in coco_data['images']}\n",
        "annotations_by_image = {}\n",
        "for ann in coco_data['annotations']:\n",
        "    img_id = ann['image_id']\n",
        "    if img_id not in annotations_by_image:\n",
        "        annotations_by_image[img_id] = []\n",
        "    annotations_by_image[img_id].append(ann)\n",
        "\n",
        "# Category ID to Name mapping\n",
        "categories = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "\n",
        "# Generate XMLs\n",
        "for image_id, anns in annotations_by_image.items():\n",
        "    create_voc_xml(image_id, anns, images[image_id], output_dir, categories)\n",
        "\n",
        "print(\"PASCAL VOC formatına dönüşüm tamamlandı!\")\n"
      ],
      "metadata": {
        "id": "RPTADpvjqQD7",
        "outputId": "0730673a-ae2d-463c-9df3-aed65f8c1f5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PASCAL VOC formatına dönüşüm tamamlandı!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from xml.etree.ElementTree import Element, SubElement, tostring\n",
        "import xml.dom.minidom as minidom\n",
        "\n",
        "def create_voc_xml(image_id, annotations, image_info, output_dir, categories):\n",
        "    # Root element\n",
        "    annotation = Element('annotation')\n",
        "    folder = SubElement(annotation, 'folder')\n",
        "    folder.text = \"images\"\n",
        "    filename = SubElement(annotation, 'filename')\n",
        "    filename.text = image_info['file_name']\n",
        "\n",
        "    # Image size\n",
        "    size = SubElement(annotation, 'size')\n",
        "    SubElement(size, 'width').text = str(image_info['width'])\n",
        "    SubElement(size, 'height').text = str(image_info['height'])\n",
        "    SubElement(size, 'depth').text = '3'\n",
        "\n",
        "    # Add bounding boxes\n",
        "    for ann in annotations:\n",
        "        obj = SubElement(annotation, 'object')\n",
        "        category_name = categories[ann['category_id']]\n",
        "        SubElement(obj, 'name').text = category_name\n",
        "        SubElement(obj, 'pose').text = 'Unspecified'\n",
        "        SubElement(obj, 'truncated').text = '0'\n",
        "        SubElement(obj, 'difficult').text = '0'\n",
        "\n",
        "        bndbox = SubElement(obj, 'bndbox')\n",
        "        bbox = ann['bbox']\n",
        "        SubElement(bndbox, 'xmin').text = str(int(bbox[0]))\n",
        "        SubElement(bndbox, 'ymin').text = str(int(bbox[1]))\n",
        "        SubElement(bndbox, 'xmax').text = str(int(bbox[0] + bbox[2]))\n",
        "        SubElement(bndbox, 'ymax').text = str(int(bbox[1] + bbox[3]))\n",
        "\n",
        "    # Write XML to file\n",
        "    xml_str = minidom.parseString(tostring(annotation)).toprettyxml(indent=\"   \")\n",
        "    xml_path = os.path.join(output_dir, f\"{image_id}.xml\")\n",
        "    with open(xml_path, \"w\") as f:\n",
        "        f.write(xml_str)\n",
        "\n",
        "# Paths\n",
        "coco_json_path = \"data_train/annotations/instances_val2017.json\"  # COCO JSON dosyasının yolu\n",
        "output_dir = \"data_train/annotations/voc_val\"  # PASCAL VOC XML dosyalarının kaydedileceği yer\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load COCO JSON\n",
        "with open(coco_json_path) as f:\n",
        "    coco_data = json.load(f)\n",
        "\n",
        "# Process images and annotations\n",
        "images = {img['id']: img for img in coco_data['images']}\n",
        "annotations_by_image = {}\n",
        "for ann in coco_data['annotations']:\n",
        "    img_id = ann['image_id']\n",
        "    if img_id not in annotations_by_image:\n",
        "        annotations_by_image[img_id] = []\n",
        "    annotations_by_image[img_id].append(ann)\n",
        "\n",
        "# Category ID to Name mapping\n",
        "categories = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "\n",
        "# Generate XMLs\n",
        "for image_id, anns in annotations_by_image.items():\n",
        "    create_voc_xml(image_id, anns, images[image_id], output_dir, categories)\n",
        "\n",
        "print(\"Doğrulama dataset'i için PASCAL VOC formatına dönüşüm tamamlandı!\")\n"
      ],
      "metadata": {
        "id": "j3rK8Et5C3dJ",
        "outputId": "5ba10f24-5c0e-4fd8-d6c9-d52faaf26d6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doğrulama dataset'i için PASCAL VOC formatına dönüşüm tamamlandı!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rMK2xemPC4WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run your training and eval script as an external python script\n",
        "%%shell\n",
        "eval \"$(conda shell.bash hook)\"\n",
        "conda activate myenv\n",
        "python /content/train.py"
      ],
      "metadata": {
        "id": "_kgUrn27byMe",
        "outputId": "d5ebf8f4-25be-447d-c007-02e8aeb36b95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-26 19:56:59.247987: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-11-26 19:56:59.248020: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/envs/myenv/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "\n",
            "Tensorflow Version:\n",
            "2.8.4\n",
            "\n",
            "2024-11-26 19:57:05.519689: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/envs/myenv/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-11-26 19:57:05.519829: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/envs/myenv/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-11-26 19:57:05.519927: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/envs/myenv/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-11-26 19:57:05.520015: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/envs/myenv/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-11-26 19:57:05.564208: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/envs/myenv/lib/python3.9/site-packages/cv2/../../lib64:/usr/local/lib/python3.10/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2024-11-26 19:57:05.564529: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2024-11-26 19:57:05.565032: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-26 19:57:16.661610: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "Epoch 1/3\n",
            "52/52 [==============================] - ETA: 0s - det_loss: 1.1989 - cls_loss: 0.6930 - box_loss: 0.0101 - reg_l2_loss: 0.0630 - loss: 1.2619 - learning_rate: 0.0237 - gradient_norm: 1.21762024-11-26 20:00:50.608967: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "52/52 [==============================] - 224s 4s/step - det_loss: 1.1892 - cls_loss: 0.6866 - box_loss: 0.0101 - reg_l2_loss: 0.0630 - loss: 1.2522 - learning_rate: 0.0240 - gradient_norm: 1.2423 - val_det_loss: 1.2020 - val_cls_loss: 0.7948 - val_box_loss: 0.0081 - val_reg_l2_loss: 0.0630 - val_loss: 1.2650\n",
            "Epoch 2/3\n",
            "52/52 [==============================] - ETA: 0s - det_loss: 0.4642 - cls_loss: 0.2491 - box_loss: 0.0043 - reg_l2_loss: 0.0631 - loss: 0.5273 - learning_rate: 0.0075 - gradient_norm: 1.22372024-11-26 20:04:03.475398: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "52/52 [==============================] - 191s 4s/step - det_loss: 0.4634 - cls_loss: 0.2490 - box_loss: 0.0043 - reg_l2_loss: 0.0631 - loss: 0.5265 - learning_rate: 0.0073 - gradient_norm: 1.2211 - val_det_loss: 0.6279 - val_cls_loss: 0.3481 - val_box_loss: 0.0056 - val_reg_l2_loss: 0.0631 - val_loss: 0.6910\n",
            "Epoch 3/3\n",
            "52/52 [==============================] - ETA: 0s - det_loss: 0.4111 - cls_loss: 0.2296 - box_loss: 0.0036 - reg_l2_loss: 0.0631 - loss: 0.4742 - learning_rate: 0.0071 - gradient_norm: 1.08002024-11-26 20:07:13.567837: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "52/52 [==============================] - 190s 4s/step - det_loss: 0.4113 - cls_loss: 0.2298 - box_loss: 0.0036 - reg_l2_loss: 0.0631 - loss: 0.4744 - learning_rate: 0.0073 - gradient_norm: 1.0889 - val_det_loss: 0.5409 - val_cls_loss: 0.3419 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0631 - val_loss: 0.6040\n",
            "6/6 [==============================] - 19s 2s/step\n",
            "\n",
            "COCO metrics:\n",
            "AP: 0.5593447685241699\n",
            "AP50: 0.9206976890563965\n",
            "AP75: 0.6415743827819824\n",
            "APs: 0.30000001192092896\n",
            "APm: 0.4289015531539917\n",
            "APl: 0.5754359364509583\n",
            "ARmax1: 0.20065420866012573\n",
            "ARmax10: 0.6222429871559143\n",
            "ARmax100: 0.6829906702041626\n",
            "ARs: 0.30000001192092896\n",
            "ARm: 0.607758641242981\n",
            "ARl: 0.6933754086494446\n",
            "AP_/Tablo: 0.5593447685241699\n",
            "\n",
            "2024-11-26 20:07:46.435757: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "2024-11-26 20:08:13.094300: W tensorflow/core/common_runtime/graph_constructor.cc:803] Node 'resample_p7/PartitionedCall' has 1 outputs but the _output_shapes attribute specifies shapes for 3 outputs. Output shapes may be inaccurate.\n",
            "2024-11-26 20:08:20.484839: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
            "2024-11-26 20:08:20.484897: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
            "2024-11-26 20:08:20.485993: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmpny3dw16z\n",
            "2024-11-26 20:08:20.618687: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
            "2024-11-26 20:08:20.618756: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmpny3dw16z\n",
            "2024-11-26 20:08:21.050218: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
            "2024-11-26 20:08:23.554386: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmpny3dw16z\n",
            "2024-11-26 20:08:24.580460: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 4094474 microseconds.\n",
            "2024-11-26 20:08:26.239636: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2024-11-26 20:08:28.104367: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
            "\n",
            "Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 0\n",
            "2024-11-26 20:10:21.110809: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
            "\n",
            "Estimated count of arithmetic ops: 1.752 G  ops, equivalently 0.876 G  MACs\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "336/336 [==============================] - 835s 2s/step\n",
            "\n",
            "COCO metrics tflite:\n",
            "AP: 0.5429996252059937\n",
            "AP50: 0.9213622808456421\n",
            "AP75: 0.5836424827575684\n",
            "APs: 0.2673267424106598\n",
            "APm: 0.4167730510234833\n",
            "APl: 0.5570601224899292\n",
            "ARmax1: 0.1989719569683075\n",
            "ARmax10: 0.6028971672058105\n",
            "ARmax100: 0.6376635432243347\n",
            "ARs: 0.2666666805744171\n",
            "ARm: 0.567241370677948\n",
            "ARl: 0.6474237442016602\n",
            "AP_/Tablo: 0.5429996252059937\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}